---
{"dg-publish":true,"permalink":"/ğŸ”è®¡é‡ç»æµå­¦/æœ€å°å¹³æ–¹ä¼°è®¡é‡çš„æ€§è´¨/","tags":["çº¿æ€§æ¨¡å‹"],"created":"2025-08-20T16:28:01.000+08:00","updated":"2025-08-20T16:28:01.000+08:00"}
---

[[ğŸ”è®¡é‡ç»æµå­¦/Linear Regression Model#æ¨¡å‹è®¾å®š\|Linear Regression Model#æ¨¡å‹è®¾å®š]]å¦‚ä¸‹
$$
\begin{gather*}
\begin{cases}
Y=X^{\mathsf{T}}{\beta}+e\\
E(e|X)=0
\end{cases} \tag{1} \\
\begin{cases}
E(Y^2)<\infty \\
E(\Vert X \Vert^2)<\infty \\
E(XX^{\mathsf{T}})\succ O
\end{cases} \tag{2}
\end{gather*}
$$
[[ğŸ”è®¡é‡ç»æµå­¦/æœ€å°å¹³æ–¹ä¼°è®¡é‡#çŸ©é˜µå½¢å¼çš„æƒ…å½¢\|æœ€å°å¹³æ–¹ä¼°è®¡é‡#çŸ©é˜µå½¢å¼çš„æƒ…å½¢]] ä¸º
$$
\hat{{\beta}}\equiv\left(\mathbf{X}^{\mathsf{T}}\mathbf{X} \right)^{-1}\left(\mathbf{X}^{\mathsf{T}}\mathbf{Y} \right)
$$
ä»¥ä¸‹ç»“è®ºå‡å‡è®¾æ ·æœ¬æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ã€‚

## æ¡ä»¶æœŸæœ›

æ ·æœ¬æ¨¡å‹å’Œæ€»ä½“æ¨¡å‹ä¸€è‡´
$$
Y_{i}=X_{i}^{\mathsf{T}}\beta+e_{i}
$$
å–æ¡ä»¶æœŸæœ›å¯å¾—
$$
E[Y_{i}\mid \mathbf{X}]=X_{i}^{\mathsf{T}}\beta+E[e_{i}|\mathbf{X}]
$$
ä»è€Œæœ‰
$$
E[\mathbf{Y}\mid \mathbf{X}]=
\begin{bmatrix}
\vdots \\
E[Y_i\mid \mathbf{X}] \\
\vdots \\
\end{bmatrix}
=
\begin{bmatrix}
\vdots \\
X_i^{\mathsf{T}}{\beta}+E[e|\mathbf{X}] \\
\vdots \\
\end{bmatrix}
=\mathbf{X}{\beta}+E[\mathbf{e}\mid \mathbf{X}]
$$
æœ€å°å¹³æ–¹ä¼°è®¡é‡çš„æ¡ä»¶æœŸæœ›ä¸º
$$
\begin{align}
E[\hat{{\beta}}\mid \mathbf{X}]
&=E\left[(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} (\mathbf{X}^{\mathsf{T}}\mathbf{Y})\mid \mathbf{X} \right] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}E\left[\mathbf{Y}\mid \mathbf{X} \right] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}(\mathbf{X}{\beta}+E[\mathbf{e}\mid \mathbf{X}]) \\
\end{align}
$$
å½“ä¸”ä»…å½“ $E(e|X)=0$ æ—¶ï¼ˆä½¿ç”¨[[ğŸ”è®¡é‡ç»æµå­¦/çº¿æ€§CEFæ¨¡å‹\|çº¿æ€§CEFæ¨¡å‹]]çš„å‡è®¾ï¼‰
$$
E[\hat{{\beta}}\mid \mathbf{X}]=\beta
$$
æˆ‘ä»¬ç§°è¿™ç§æ€§è´¨ä¸º**æ— åæ€§**ï¼ˆunbiasnessï¼‰ã€‚

If $(X,e)$ have a joint normal distribution[^1]ï¼Œæ ¹æ®æœŸæœ›è¿­ä»£æ³•åˆ™æœ‰
$$
E({\beta})=E[E[\hat{{\beta}}\mid \mathbf{X}]\mid X]=E[{\beta}\mid \mathbf{X}]={\beta}
$$
[^1]: è¿™æ˜¯ä¸€ä¸ªå……åˆ†ä¸å¿…è¦æ¡ä»¶ï¼›å¦‚æœ $X$ æœä»ç¦»æ•£å‹åˆ†å¸ƒï¼Œ$\hat{{\beta}}$ çš„æœŸæœ›å’Œæ–¹å·®å¯èƒ½ä¸å­˜åœ¨ã€‚

## æ¡ä»¶æ–¹å·®

æœ€å°å¹³æ–¹ä¼°è®¡é‡çš„æ¡ä»¶æ–¹å·®ä¸º
$$
\begin{align}
Var[\hat{{\beta}}\mid \mathbf{X}]
&=Var[(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} (\mathbf{X}^{\mathsf{T}}\mathbf{Y})|\mathbf{X}] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{Y}\mid \mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{X}{\beta}+\mathbf{e}\mid \mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{e}|\mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
\end{align}
$$
ä¸ºäº†è¡¨ç¤ºæ–¹ä¾¿ï¼Œå®šä¹‰
$$
\boldsymbol{\Omega}\equiv Var(\mathbf{e}\mid \mathbf{X})
$$
å½“ä¸”ä»…å½“ $E(e|X)=0$ æ—¶ï¼ˆä½¿ç”¨[[ğŸ”è®¡é‡ç»æµå­¦/çº¿æ€§CEFæ¨¡å‹\|çº¿æ€§CEFæ¨¡å‹]]çš„å‡è®¾ï¼‰
$$
\boldsymbol{\Omega}=E[\mathbf{e}\mathbf{e}^{\mathsf{T}}\mid \mathbf{X}]-E[\mathbf{e}\mid \mathbf{X}]E[\mathbf{e}\mid \mathbf{X}]^{\mathsf{T}}=E[\mathbf{e}\mathbf{e}^{\mathsf{T}}\mid \mathbf{X}]=\begin{bmatrix}
\sigma_{11}^2 & \cdots & \sigma_{1n}^{2}\\
\vdots & \ddots & \vdots\\
\sigma_{n 1}^{2} & \cdots & \sigma_{nn}^2
\end{bmatrix}
$$
å…¶ä¸­ï¼Œä¸»å¯¹è§’çº¿å…ƒç´ ä¸ºæ ·æœ¬è¯¯å·®çš„æ–¹å·®ï¼Œå…¶ä»–å…ƒç´ ä¸ºæ ·æœ¬è¯¯å·®ä¹‹é—´çš„åæ–¹å·®ã€‚
$$
\begin{align}
\sigma ^{2}_{ii} & =E[e_{i}^{2}|\mathbf{X}] =E[e_{i}^{2}|\mathbf{X}]-E[e_{i}\mid \mathbf{X}]^{2}=Var(e_{i}\mid \mathbf{X}) \\
\sigma^{2}_{ij} & =E[e_{i}e_{j}\mid \mathbf{X}]=E[e_{i}e_{j}\mid \mathbf{X}]-E[e_{i}\mid \mathbf{X}]E[e_{j}\mid \mathbf{X}]=Cov(e_{i},e_{j}\mid \mathbf{X})
\end{align}
$$
å› æ­¤ï¼Œ$\boldsymbol{\Omega}$ ä¹Ÿç§°ä¸ºæ ·æœ¬è¯¯å·®çš„**æ–¹å·®-åæ–¹å·®çŸ©é˜µ**ã€‚

ç”±äº $\boldsymbol{\Omega}$ çŸ©é˜µåŒ…å«è¶³è¶³ $n\times n$ ä¸ªæœªçŸ¥å‚æ•°ï¼Œæˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨å‡ ç§å‡è®¾å‡å°‘æœªçŸ¥å‚æ•°æ•°é‡ï¼š
- ä¸»å¯¹è§’çº¿å…ƒç´ 
	- åŒè´¨æ€§ï¼ˆhomogeneityï¼‰ï¼š$\sigma^{2}_{ii}=\sigma^{2}$
	- å¼‚è´¨æ€§ï¼ˆheterogeneityï¼‰ï¼š$\sigma^{2}_{ii}=\sigma_{i}^{2}$
- å…¶ä»–å…ƒç´ 
	- æ— å…³æ€§ï¼ˆuncorrelatedï¼‰ï¼š$\sigma^{2}_{ij}=0$
	- ç›¸å…³æ€§ï¼ˆcorrelatedï¼‰ï¼š$\sigma^{2}_{ij}\neq 0$
		- å¯¹äºåˆ†ç»„æ•°æ®ï¼Œè‹¥ $Cov(e_{i,g},e_{j,g})\neq 0$ï¼Œç§°åˆ†ç»„ $g$ å­˜åœ¨èšç±»ç›¸å…³ï¼ˆcluster-correlatedï¼‰
		- å¯¹äºæ—¶åºæ•°æ®ï¼Œè‹¥ $e_{t}=\rho e_{t-1}+\varepsilon$ ï¼Œç§°æ—¶åºå­˜åœ¨ï¼ˆä¸€é˜¶ï¼‰è‡ªç›¸å…³ï¼ˆauto-correlatedï¼‰

åœ¨æ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒæ¡ä»¶ä¸‹ï¼Œå…¶ä»–å…ƒç´ å¤©ç„¶æ»¡è¶³æ— å…³æ€§ï¼Œæ‰€ä»¥ä¸¤ç§ç»„åˆå‡è®¾æœ€ä¸ºå¸¸ç”¨ï¼š
- åŒè´¨æ€§+æ— å…³æ€§=åŒæ–¹å·®ï¼ˆhomoskedasticityï¼‰
$$
\boldsymbol{\Omega}=\begin{bmatrix}
\sigma^2 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \sigma^2
\end{bmatrix}=\sigma^{2}\mathbf{I}_{n}
$$
- å¼‚è´¨æ€§+æ— å…³ç³»=å¼‚æ–¹å·®ï¼ˆheteroskedasticityï¼‰
$$
\boldsymbol{\Omega}=\begin{bmatrix}
\sigma_1^2 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \sigma_n^2
\end{bmatrix}
$$
ä¾‹å¦‚ï¼ŒåŒæ–¹å·®å‡è®¾ä¸‹æœ€å°å¹³æ–¹ä¼°è®¡é‡çš„æ¡ä»¶æ–¹å·®ä¸º
$$
Var[\hat{{\beta}}\mid \mathbf{X}]=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\sigma^{2}
$$
äº‹å®ä¸Šï¼Œè¿™æ˜¯ $\beta$ çš„ä¸€æ—ä¼°è®¡é‡æ‰€èƒ½è¾¾åˆ°çš„æœ€å°æ–¹å·®ã€‚

**Gauss-Markov Theorem** Take the homoskedastic linear regression model. If $\tilde{{\beta}}$ is an linear unbiased estimator of ${\beta}$, then
$$
Var[\tilde{{\beta}}\mid \mathbf{X}]\ge (\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\sigma^{2}
$$
å³æœ€å°å¹³æ–¹ä¼°è®¡é‡åœ¨æ‰€æœ‰çº¿æ€§æ— åä¼°è®¡é‡ä¸­æ¡ä»¶æ–¹å·®æœ€å°ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿æˆ‘ä»¬é‡‡ç”¨æœ€ä¸ºä¾¿åˆ©çš„åŒæ–¹å·®å‡è®¾ï¼Œä¹Ÿä»…èƒ½å°† $\boldsymbol{\Omega}$ çŸ©é˜µçš„æœªçŸ¥å‚æ•°å‡å°‘åˆ°åªå‰© $\sigma ^{2}$ï¼Œæˆ‘ä»¬ä»æœªè§£å†³å¦‚ä½•ä½¿ç”¨æ ·æœ¬æ•°æ®ä¼°è®¡æ¡ä»¶æ–¹å·®çš„é—®é¢˜ï¼Œè¿›ä¸€æ­¥è®¨è®ºè¯¦è§[[ğŸ”è®¡é‡ç»æµå­¦/å›å½’è¯¯å·®å‚æ•°çš„ä¼°è®¡\|å›å½’è¯¯å·®å‚æ•°çš„ä¼°è®¡]]ã€‚

## ç»å…¸çº¿æ€§æ¨¡å‹å‡è®¾

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»èµ°è¿‡äº†ä»æ„å»ºæ€»ä½“çº¿æ€§å›å½’æ¨¡å‹åˆ°å¾—å‡ºæ ·æœ¬ä¼°è®¡é‡åŠå…¶æ€§è´¨çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸã€‚æ€»ç»“ä¸€ä¸‹ç›¸å…³å‡è®¾ã€‚

| åºå·  | å‡è®¾         | å†…æ¶µ                                                                      |
| --- | ---------- | ----------------------------------------------------------------------- |
| â‘    | çº¿æ€§æ¨¡å‹       | $Y=X\beta+e$                                                            |
| â‘¡   | å‡å€¼ç‹¬ç«‹       | $E[e\mid X]=0$                                                          |
| â‘¢   | éšæœºæŠ½æ ·       | æ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒ                                                                 |
| â‘£   | è§£é‡Šå˜é‡ä¸å®Œå…¨å…±çº¿  | $E(XX^{\mathsf{T}}) \text{ is positive definite.}$                      |
| â‘¤   | è¯¯å·®é¡¹æ»¡è¶³åŒæ–¹å·®å‡è®¾ | $Var[\mathbf{e}\mid\mathbf{X}]=\sigma^{2} \mathbf{I}_{n}$               |
| â‘¥   | è¯¯å·®é¡¹æœä»æ­£æ€åˆ†å¸ƒ  | $\mathbf{e}\mid\mathbf{X}\sim \mathcal{N}(0,\sigma^{2} \mathbf{I}_{n})$ |

> [!tip]
> â‘ -â‘¤ç§°ä¸º Gaussâ€“Markov assumptions
> â‘ -â‘¥ç§°ä¸º classical linear model assumptions
> 
> â‘ -â‘£å³å¯å¾—å‡ºæ— åæ€§ã€‚â‘¤å¯å¾—å‡ºå‚æ•°ä¼°è®¡é‡çš„ç†æƒ³æ¡ä»¶æ–¹å·®ä½†å¹¶ä¸ç°å®ï¼Œå› æ­¤æœ‰å¿…è¦ä½¿ç”¨å„ç§ç¨³å¥æ ‡å‡†è¯¯ã€‚â‘¥ç”¨äºç»Ÿè®¡æ¨æ–­ä½†ç›´æ¥å‡è®¾ç¼ºä¹è¯´æœåŠ›ï¼Œæœ€å¥½å€ŸåŠ©ä¸­å¿ƒæé™å®šç†å’Œæ¸è¿›ç†è®ºã€‚
> 

```mermaid
flowchart LR
    ç»Ÿè®¡æ¨æ–­-->æ ‡å‡†è¯¯
    ç»Ÿè®¡æ¨æ–­-->æ­£æ€åˆ†å¸ƒ
    æ ‡å‡†è¯¯--åŒæ–¹å·®å‡è®¾-->ç®€å•æ ‡å‡†è¯¯
    æ ‡å‡†è¯¯--å¼‚æ–¹å·®å‡è®¾-->ç¨³å¥æ ‡å‡†è¯¯
    æ­£æ€åˆ†å¸ƒ-->å¤§èƒ†å‡è®¾
    æ­£æ€åˆ†å¸ƒ-->æ¸è¿›ç†è®º

```

> [!quote]
> The CLM assumptions are very strong, and a primary focus in theoretical and applied econometrics has been to conduct inference using OLS in a variety of settings â€“ cross-sectional data, time series data, panel data, and data with a spatial structure â€“ while imposing few assumptions. It is very difficult to get anywhere without relying on asymptotics. Therefore, we replace the CLM assumptions and rely on application of the law of large numbers and central limit theorem.(Wooldridge,2023)

## æ¸è¿›æ€§è´¨

