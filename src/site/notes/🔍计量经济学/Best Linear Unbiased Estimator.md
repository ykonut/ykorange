---
{"dg-publish":true,"permalink":"/ğŸ”è®¡é‡ç»æµå­¦/Best Linear Unbiased Estimator/","created":"2025-08-20T11:56:52.000+08:00","updated":"2025-08-20T11:56:52.000+08:00"}
---

[[ğŸ”è®¡é‡ç»æµå­¦/Linear Regression Model#æ¨¡å‹è®¾å®š\|Linear Regression Model#æ¨¡å‹è®¾å®š]]å¦‚ä¸‹
$$
\begin{gather*}
\begin{cases}
Y=X^{\mathsf{T}}{\beta}+e\\
E(e|X)=0
\end{cases} \tag{1} \\
\begin{cases}
E(Y^2)<\infty \\
E(\Vert X \Vert^2)<\infty \\
E(XX^{\mathsf{T}})\succ O
\end{cases} \tag{2}
\end{gather*}
$$
[[ğŸ”è®¡é‡ç»æµå­¦/Least Squares Estimator#çŸ©é˜µå½¢å¼çš„æƒ…å½¢\|Least Squares Estimator#çŸ©é˜µå½¢å¼çš„æƒ…å½¢]] ä¸º
$$
\hat{{\beta}}\equiv\left(\mathbf{X}^{\mathsf{T}}\mathbf{X} \right)^{-1}\left(\mathbf{X}^{\mathsf{T}}\mathbf{Y} \right)
$$

## Expectation of LS Estimator

è‹¥æ ·æœ¬æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œåˆ™æœ‰
$$
E[Y_i\mid X_1,\ldots,X_n]=E[Y_i\mid X_i]=X_i^{\mathsf{T}}{\beta}
$$
ä»è€Œæœ‰ï¼ˆéœ€è¦ç”¨åˆ° $E[e\mid X]=0$ï¼‰
$$
E[\mathbf{Y}\mid \mathbf{X}]=
\begin{bmatrix}
\vdots \\
E[Y_i\mid \mathbf{X}] \\
\vdots \\
\end{bmatrix}
=
\begin{bmatrix}
\vdots \\
X_i^{\mathsf{T}}{\beta} \\
\vdots \\
\end{bmatrix}
=\mathbf{X}{\beta}
$$
å‚æ•°ä¼°è®¡é‡çš„æ¡ä»¶æœŸæœ›ä¸º
$$
\begin{align}
E[\hat{{\beta}}\mid \mathbf{X}]
&=E\left[(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}\mathbf{Y}\mid \mathbf{X} \right] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}E\left[\mathbf{Y}\mid \mathbf{X} \right] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}\mathbf{X}{\beta} \\
&={\beta}
\end{align}
$$
If $(X,e)$ have a joint normal distribution[^1]ï¼Œæ ¹æ®æœŸæœ›è¿­ä»£æ³•åˆ™æœ‰
$$
E({\beta})=E[E[\hat{{\beta}}\mid \mathbf{X}]\mid X]=E[{\beta}\mid \mathbf{X}]={\beta}
$$
[^1]: è¿™æ˜¯ä¸€ä¸ªå……åˆ†ä¸å¿…è¦æ¡ä»¶ï¼›å¦‚æœ $X$ æœä»ç¦»æ•£å‹åˆ†å¸ƒï¼Œ$\hat{{\beta}}$ çš„æœŸæœ›å’Œæ–¹å·®å¯èƒ½ä¸å­˜åœ¨ã€‚

## Variance of LS Estimator

å‚æ•°ä¼°è®¡é‡çš„æ¡ä»¶æ–¹å·®ä¸º
$$
\begin{align}
Var[\hat{{\beta}}\mid \mathbf{X}]
&=Var[(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}\mathbf{Y}|\mathbf{X}] \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{Y}\mid \mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{X}{\beta}+\mathbf{e}\mid \mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}Var[\mathbf{e}|\mathbf{X}]\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1} \\
&=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\mathbf{X}^{\mathsf{T}}\boldsymbol{\Omega}\mathbf{X}(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}
\end{align}
$$
ç‰¹åˆ«åœ°ï¼Œè‹¥è¯¯å·®é¡¹æ»¡è¶³åŒæ–¹å·®ï¼ˆhomoskedasticï¼‰å‡è®¾ï¼Œå³
$$
\boldsymbol{\Omega}=Var[\mathbf{e}|\mathbf{X}]=\sigma^{2} \mathbf{I}_{n}
$$
åˆ™å‚æ•°ä¼°è®¡é‡çš„æ¡ä»¶æ–¹å·®ä¸º
$$
Var[\hat{{\beta}}\mid \mathbf{X}]=(\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\sigma^{2}
$$
**Gauss-Markov Theorem** Take the homoskedastic linear regression model. If $\tilde{{\beta}}$ is an linear unbiased estimator of ${\beta}$ then
$$
Var[\tilde{{\beta}}\mid \mathbf{X}]\ge (\mathbf{X}^{\mathsf{T}}\mathbf{X})^{-1}\sigma^{2}
$$
å³ Least Squares Estimator æ˜¯æ‰€æœ‰çº¿æ€§æ— åä¼°è®¡é‡ä¸­æ¡ä»¶æ–¹å·®æœ€å°çš„ã€‚

ç„¶è€Œï¼ŒåŒæ–¹å·®å‡è®¾åœ¨å®è·µä¸­å‡ ä¹ä¸å¯èƒ½æ»¡è¶³ï¼›å³ä½¿æ»¡è¶³ï¼Œ $\sigma^{2}$ ä¹Ÿæ˜¯æœªçŸ¥å‚æ•°ï¼Œæ— æ³•ç”¨äºè®¡ç®—å‚æ•°ä¼°è®¡é‡çš„æ ‡å‡†è¯¯ï¼ˆ$SE[\hat{\beta}\mid \mathbf{X}]$ï¼‰ç”¨äºç»Ÿè®¡æ¨æ–­ã€‚å› æ­¤ï¼Œæœ‰å¿…è¦æ„å»º $\sigma^{2}$ çš„ä¼°è®¡é‡å’ŒéåŒæ–¹å·®å‡è®¾ä¸‹å‚æ•°ä¼°è®¡é‡çš„æ¡ä»¶æ–¹å·®ã€‚

ğŸ‘‰ [[ğŸ”è®¡é‡ç»æµå­¦/Homoskedasticity and Heteroskedasticity\|Homoskedasticity and Heteroskedasticity]]

## åŸºæœ¬å‡è®¾ä¸æ¨¡å‹æ€§è´¨

| åºå· | å‡è®¾                 | è¡¨è¾¾å¼         |
| ---- | -------------------- | -------------- |
| â‘     | çº¿æ€§æ¨¡å‹             | $Y=X\beta+e$   |
| â‘¡    | é›¶æ¡ä»¶å‡å€¼           | $E[e\mid X]=0$ | 
| â‘¢    | éšæœºæŠ½æ ·             |                |
| â‘£    | è§£é‡Šå˜é‡ä¸å®Œå…¨å…±çº¿   |                |
| â‘¤    | è¯¯å·®é¡¹æ»¡è¶³åŒæ–¹å·®å‡è®¾ | $Var[\mathbf{e}\mid\mathbf{X}]=\sigma^{2} \mathbf{I}_{n}$|
| â‘¥    | è¯¯å·®é¡¹æœä»æ­£æ€åˆ†å¸ƒ   | $\mathbf{e}\mid\mathbf{X}\sim \mathcal{N}(0,\sigma^{2} \mathbf{I}_{n})$ |


> [!tip]
> â‘ -â‘¤ç§°ä¸º Gaussâ€“Markov assumptions
> â‘ -â‘¥ç§°ä¸º classical linear model assumptions
> 
> â‘ â‘¡æ„æˆäº† [[ğŸ”è®¡é‡ç»æµå­¦/Linear CEF Model\|Linear CEF Model]] ï¼Œâ‘¢ä¿è¯äº†æ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œâ‘£ä¿è¯äº†å‚æ•°ä¼°è®¡é‡æœ‰æ•°å€¼è§£ï¼Œâ‘ -â‘£å³å¯å¾—å‡ºæ— åæ€§ã€‚â‘¤å¯å¾—å‡ºå‚æ•°ä¼°è®¡é‡çš„ç†æƒ³æ¡ä»¶æ–¹å·®ä½†å¹¶ä¸ç°å®ï¼Œå› æ­¤æœ‰å¿…è¦ä½¿ç”¨å„ç§ç¨³å¥æ ‡å‡†è¯¯ã€‚â‘¥ç”¨äºç»Ÿè®¡æ¨æ–­ä½†ç›´æ¥å‡è®¾ç¼ºä¹è¯´æœåŠ›ï¼Œæœ€å¥½å€ŸåŠ©ä¸­å¿ƒæé™å®šç†å’Œæ¸è¿›ç†è®ºã€‚
> 

```mermaid
flowchart LR
    ç»Ÿè®¡æ¨æ–­-->æ ‡å‡†è¯¯
    ç»Ÿè®¡æ¨æ–­-->æ­£æ€åˆ†å¸ƒ
    æ ‡å‡†è¯¯--åŒæ–¹å·®å‡è®¾-->ç®€å•æ ‡å‡†è¯¯
    æ ‡å‡†è¯¯--å¼‚æ–¹å·®å‡è®¾-->ç¨³å¥æ ‡å‡†è¯¯
    æ­£æ€åˆ†å¸ƒ-->å¤§èƒ†å‡è®¾
    æ­£æ€åˆ†å¸ƒ-->æ¸è¿›ç†è®º

```

> [!quote]
> The CLM assumptions are very strong, and a primary focus in theoretical and applied econometrics has been to conduct inference using OLS in a variety of settings â€“ cross-sectional data, time series data, panel data, and data with a spatial structure â€“ while imposing few assumptions. It is very difficult to get anywhere without relying on asymptotics. Therefore, we replace the CLM assumptions and rely on application of the law of large numbers and central limit theorem.(Wooldridge,2023)

## æ¸è¿›æ€§è´¨

