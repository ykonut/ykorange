---
{"dg-publish":true,"permalink":"/微观经济学/信息经济学/道德风险/","created":"2024-10-12T10:25:06.000+08:00","updated":"2024-10-12T10:25:06.000+08:00"}
---


![道德风险1.svg](https://raw.githubusercontent.com/ykonut/picx-images-hosting/master/picgo/image-328fc50b5bf88f7281fb22cf400b3f80.svg)
相较于[[微观经济学/信息经济学/基准模型\|基准模型]]，道德风险情形下代理人的努力程度不可证实。假设代理人为风险中性，最优合约本应为固定报酬，但此时代理人必然选择最低的努力程度，导致委托人的利润相较于信息对称时偏低。因此，为了激励代理人选择更高的努力程度需要额外的约束。

## 一般模型

最优合约选择问题为
$$
\begin{align}
\max_{\{ e,w(\cdot) \}} &\ \sum\limits_{i=1}^{n}p(x_{i}\mid e) B(x_{i}-w(x_{i}))\\
\text{s.t.} &\ \sum\limits_{i=1}^{n}p(x_{i}\mid e)u(w(x_{i}))-c(e)\geq \bar{u}\\
&\ e\in \mathop{\arg\max}\limits_{\hat{e}}\sum\limits_{i=1}^{n}p(x_{i}\mid \hat{e})u(w(x_{i}))-c(\hat{e})
\end{align}
$$
- 第一个约束是**参与约束**（或个人理性约束）
- 第二个约束是**激励相容约束**（incentive-compatibility constraint）

当努力程度是连续变量时该问题很难分析，因为目标函数关于 $e$ 并不必然是凹的，除非对条件概率函数的形式施加额外假设。因此我们先考虑该模型的简化版本。

## 二值离散模型

考虑努力程度是离散变量的情形。令 $e\in \{ e^H,e^L \}$ ，令 $p_{i}^H\equiv p(x_{i}\mid e^H)$ 以及 $p_{i}^L\equiv p(x_{i}\mid e^L)$ ，设 $p^H$ 一阶[[微观经济学/随机占优\|随机占优]]于 $p^L$，即
$$
\sum\limits_{i=1}^{k}p_{i}^H<\sum\limits_{i=1}^{k}p_{i}^L \text{ for all }k=1,\dots,n-1
$$
相当于假设高努力结果的期望效用大于等于低努力结果的期望效用。

进一步假设**委托人希望激励代理人选择高努力**，此时激励相容约束为
$$
\begin{align}
\sum\limits_{i=1}^{n}p_{i}^H u(w(x_{i}))-c(e^H) & \geq \sum\limits_{i=1}^{n} p_{i}^L u(w(x_{i}))-c(e^L) \\
\sum\limits_{i=1}^{n} [p_{i}^H-p_{i}^L]u(w(x_{i})) & \geq c(e^H)-c(e^L)
\end{align}
$$
最优合约选择问题为
$$
\begin{align}
\max_{\{ e,w(\cdot) \}} &\ \sum\limits_{i=1}^{n}p_{i}^H B(x_{i}-w(x_{i}))\\
\text{s.t.} &\ \sum\limits_{i=1}^{n}p_{i}^H u(w(x_{i}))-c(e^H)\geq \bar{u}\\
&\ \sum\limits_{i=1}^{n} [p_{i}^H-p_{i}^L]u(w(x_{i})) \geq c(e^H)-c(e^L)
\end{align}
$$
Lagrangian 函数为
$$
\begin{align}
\mathcal{L}= & \sum\limits_{i=1}^{n}p_{i}^H B(x_{i}-w(x_{i}))+\lambda \left[ \sum\limits_{i=1}^{n}p_{i}^H u(w(x_{i}))-c(e^H)-\bar{u} \right] \\
 & +\mu \left[ \sum\limits_{i=1}^{n} [p_{i}^H-p_{i}^L]u(w(x_{i})) - c(e^H) + c(e^L) \right] \\
\end{align}
$$
F.O.C.
$$
\frac{\partial \mathcal{L}}{\partial w(x_{i})}=-p_{i}^H B'(x_{i}-w(x_{i}))+\lambda p_{i}^Hu'(w(x_{i}))+\mu[p_{i}^H-p_{i}^L]u'(w(x_{i}))=0
$$
整理得
$$
\frac{B'(x_{i}-w(x_{i}))}{u'(w(x_{i}))}=\lambda+\mu \frac{p_{i}^H-p_{i}^L}{p_{i}^H}
$$
作为对比，[[微观经济学/信息经济学/基准模型\|基准模型]]相应的等式右边仅有 $\lambda$，因此第二项体现了道德风险的影响。

假设委托人是风险中性的，则上式退化为
$$
\begin{align}
\frac{1}{u'(w(x_{i}))}  & = \lambda+\mu\left( 1-\frac{p_{i}^L}{p_{i}^H} \right) \\
w(x_{i}) & =(u')^{-1}\left[ \frac{1}{\lambda+\mu\left( 1-\frac{p_{i}^L}{p_{i}^H} \right)} \right]
\end{align}
$$
当 $p_{i}^L=p_{i}^H$ 时，即对与努力程度无关的那些结果 $x_{i}$，$w(x_{i})=\bar{w}$；
当 $p_{i}^L>p_{i}^H$ 时，即对更可能是低努力的那些结果 $x_{i}$，$w(x_{i})<\bar{w}$；
当 $p_{i}^L<p_{i}^H$ 时，即对更可能是高努力的那些结果 $x_{i}$，$w(x_{i})>\bar{w}$。

因此，如果要对更好的结果给予更高的报酬，就要求 $\frac{p_{i}^L}{p_{i}^H}$ 关于 $x_{i}$ 是递减的。然而，这个条件并不能从一阶随机占优假设导出。

## 线性连续模型

当努力程度是连续变量时，对于某些特定的条件概率函数，可以直接使用激励相容约束的一阶条件代替该约束。较为简单的一种满足如下线性条件
$$
p(x_{i}\mid e)=ep_{i}^H+(1-e)p_{i}^L
$$
其中努力程度 $e\in(0,1)$ 相当于二值离散情形的混合策略。

激励相容约束为
$$
\max_{e} \sum\limits_{i=1}^{n}[ep_{i}^H+(1-e)p_{i}^L]u(w(x_{i}))-c(e)
$$
F.O.C.
$$
\sum\limits_{i=1}^{n}[p_{i}^H-p_{i}^L]u(w(x_{i}))=c'(e)
$$
最优合约选择问题为
$$
\begin{align}
\max_{\{ e,w(\cdot) \}} &\ \sum\limits_{i=1}^{n} [ep_{i}^H+(1-e)p_{i}^L] B(x_{i}-w(x_{i}))\\
\text{s.t.} &\ \sum\limits_{i=1}^{n} [ep_{i}^H+(1-e)p_{i}^L] u(w(x_{i}))-c(e)\geq \bar{u}\\
&\ \sum\limits_{i=1}^{n} [p_{i}^H-p_{i}^L]u(w(x_{i}))=c'(e)
\end{align}
$$
(最优化过程略)
整理得
$$
\frac{B'(x_{i}-w(x_{i}))}{u'(w(x_{i}))}=\lambda+\mu\frac{ p_{i}^H-p_{i}^L}{[ep_{i}^H+(1-e)p_{i}^L]}
$$
如果要对更好的结果给予更高的报酬，就要求 $\frac{ p_{i}^H-p_{i}^L}{[ep_{i}^H+(1-e)p_{i}^L]}$ 关于 $x_{i}$ 是递增的。