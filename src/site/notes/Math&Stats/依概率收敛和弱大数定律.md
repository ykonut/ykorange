---
{"dg-publish":true,"permalink":"/Math&Stats/依概率收敛和弱大数定律/","created":"2025-12-19 09:41","updated":"2025-12-19 17:28"}
---


## 依概率收敛

**定义** 若随机变量序列 $\{X_{n}\}$ 和另一个随机变量 $X$ 对于任意 $\varepsilon>0$ 满足

$$
\lim_{n\to \infty}P(|X_{n}-X |>\varepsilon)=0
$$

则称该序列依概率收敛（convergence in probability）于 $X$，记作 $X_{n}\stackrel{p}{\to}X$

**定理** 若 $\{X_n\}$ 和 $\{Y_{n}\}$ 是两个随机变量序列，满足 $X_{n}\stackrel{p}{\to}a$ 和 $Y_{n}\stackrel{p}{\to}b$，而 $g(\cdot)$ 是一个连续函数，则
1. $g(X_{n})\stackrel{p}{\to}g(a)$
2. $X_{n}+Y_{n}\stackrel{p}{\to}a+b$
3. $X_{n}Y_{n}\stackrel{p}{\to}ab$
4. $\frac{X_{n}}{Y_{n}}\stackrel{p}{\to} \frac{a}{b}$ if $b>0$

## 弱大数定律

**定理** 若 $X$ 是一个随机变量，方差 $\sigma^{2}$ 有限（因此期望 $\mu$ 有限），其 i.i.d 样本设为 $\{X_{1},\dots,X_{n}\}$ ，则样本均值 $\bar{X}_{n}=\frac{1}{n}\sum_{i}^n X_{i}$ 满足

$$
\bar{X}_{n}\stackrel{p}{\to}\mu
$$

**证明** 根据定义可知 $E(\bar{X}_n)=\mu$ 以及 $Var(\bar{X}_n)=\frac{\sigma
{ #2}
}{n}$，使用 [[Math&Stats/概率不等式#Chebyshev’s inequality\|Chebyshev’s inequality]]

$$
P(\lvert \bar{X}_{n}-\mu \rvert \geq t)\leq \frac{Var(\bar{X}_n)}{t^2}=\frac{\sigma^2}{n t^2}
$$

当 $n\to \infty$ 时，不等式右侧趋近于零，证毕。

**定理** 样本 $k$ 阶中心距依概率收敛于总体 $k$ 阶中心距

$$
\frac{1}{n}\sum_{i=1}^n(X_{i}-\bar{X}_{n})^k\stackrel{p}{\to}E(X-\mu)^k
$$

**证明**

$$
\begin{align}
\frac{1}{n}\sum_{i=1}^n(X_{i}-\bar{X}_{n})^k
&=\frac{1}{n}\sum_{i=1}^n\left[ \sum_{j=0}^k\binom{n}{k} X_{i}^j (-\bar{X}_{n})^{k-j} \right]  \\
&=\sum_{j=0}^k\left[ \binom{n}{k}\left( \frac{1}{n}\sum_{i=1}^n X_{i}^j \right)(-\bar{X}_{n})^{k-j} \right]  \\
&\stackrel{p}{\to}\sum_{j=0}^k \left[ \binom{n}{k} E(X^j)(-\mu)^{k-j} \right]=E(X-\mu)^k
\end{align}
$$

特别地，样本方差依概率收敛于总体方差：

$$
\begin{align}
\frac{1}{n-1}\sum_{i=1}^n(X_{i}-\bar{X}_{n})^2 & \stackrel{p}{\to}E(X-\mu)^2 \\
s^2 & \overset{p}{\to} \sigma^{2}
\end{align}
$$

根据依概率收敛的性质，显然也有 $s \overset{p}{\to} \sigma$
